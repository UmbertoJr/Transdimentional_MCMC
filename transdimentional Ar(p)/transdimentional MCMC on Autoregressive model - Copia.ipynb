{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Model Selection Ar(p) by transdimensional MCMC </center> </h1>\n",
    "\n",
    "### Intro to Bayesian model selection using MCMC\n",
    "\n",
    "Suppose that we want to choose the best model that fits our data $y$ using a bayesian approach to the problem. Then we have to define a joint distribution on the Model space $(M,\\mathbf{M}, \\nu())$ and in a natural hierarchical structure expressed by the parameter space given the model m $(\\Theta, \\mathbf{\\Theta}, p())$ and the observed space given model and parameters $(\\Omega, \\mathbf{\\Theta}, f())$.\n",
    "\n",
    "$$P\\{M = m, \\Theta = \\theta, Y = y\\} = \\nu(m) \\cdot p(\\theta |\\; M=m) \\cdot f(y |\\; \\theta, m)$$\n",
    "\n",
    "that is, the product of model probability, prior and likelihood.\n",
    "Given this setup, is easy to obtain:\n",
    "\n",
    "$$P\\{ M= m |\\; Y=y\\}  = \\frac{\\nu(m) \\int_{\\Omega} p(\\theta |\\;M=m) \\cdot f(y |\\; \\theta, m)d\\theta }{ \\sum_{m \\in M}\\nu(m) \\int_{\\Omega} p(\\theta |\\;M=m) \\cdot f(y |\\; \\theta, m)d\\theta}$$\n",
    "\n",
    "\n",
    "We can note that the integral that computes the marginal $f(y|\\;m)$ is only analytically tractable in certain restricted examples, and a further problem is that the size of the set of possible models M may be great that the calculation or the approximation of $f(y|m)$ for all $m\\in M$ becomes infeasible. Therefore MCMC methods which generate observations from the joint posterior of $(m, \\theta_m)$ have become popular for estimating $\\nu(m |\\;y)$ and $p(\\theta |\\;m , y)$ \n",
    "\n",
    "\n",
    "## MCMC Model Selection Methods\n",
    "\n",
    "\n",
    "<h3> <center>   Reversible jump MCMC  </center> </h3>\n",
    "\n",
    "The main property that Green's method wants to exploit is detailed balance condition that is not a necessary condition\n",
    "for ergodicity but together with aperiodicity and irreducibility it's enough to ensure ergodicity.\n",
    "\n",
    "$$\\int_A \\int_B \\pi(dx)\\; P(x, dx^{'}) = \\int_B \\int_A \\pi(dx^{'})\\; P(x^{'}, dx)$$\n",
    "\n",
    "This is the setup also for the Hastings method, that propose a new values $x_T^{'}$ from an arbitrary distribution $q_T(x_T^{'}; x_T)$, and accept the proposed values with probability:\n",
    "\n",
    "$$\\alpha( x, x^{'}) = min \\Bigg\\{ 1 , \\frac{\\pi(x_{T}^{'}; x_{-T})\\; q(x_T; x^{'})}{\\pi(x_{T}; x_{-T}^{'})\\; q(x_T^{'}; x)}\\Bigg\\}$$\n",
    "\n",
    "otherwise, the existing values are reatined.\n",
    "\n",
    "The Reversible Jump MCMC can be seen as an extension of the Metropolis-Hasting since we still want that the detailed balance condition is verified, but with jumps from samples in different dimensionality.\n",
    "So given ${C_k}$ the subspaces of different dimensionality and $C$ the combined parameter space; when the current state is $x$, we propose a move of type $m$, that would take the state to $dx^{'}$, with probability $q_m(x , \\; dx^{'})$. For the moment, this is an arbitrary sub-probability measure on $m$ and $x^{'}$. Thus $\\sum_m q_m(x, \\; C) < 1$, and with probability $1 - \\sum_m q_m(x, \\; C)$, no change to the present state is proposed. Not all moves $m$ will be available from all starting states $x$, so for each $x$, for some m we have $q_m(x , dx^{'}) = 0$.\n",
    "\n",
    "The transition kernel for such setup can be written as:\n",
    "\n",
    "$$P\\{x , B \\} = \\sum_m \\int_B q_m(x, dx^{'})\\cdot \\alpha_m(x , x^{'})  \\; + s(x)I(x \\in B)$$ \n",
    "\n",
    "where: $s(x): \\sum_m \\int_C q_m(x, dx^{'})\\cdot (1 - \\alpha_m(x , x^{'}))  \\; + 1 - \\sum_m q_m(x, \\; C)$ and $\\alpha_m(x, x^{'})$ is the acceptance probability of MH algorithm.\n",
    "\n",
    "\n",
    "So to achieve detailed balance relation, we need:\n",
    "\n",
    "$$\\sum_m \\int_A \\pi(dx) \\int_B q_m(x , dx^{'}) \\, \\alpha_m(x, x^{'}) + \\int_{A\\cap B} \\pi(dx)\\, s(x)  =  \n",
    "\\sum_m \\int_B \\pi(dx^{'}) \\int_A q_m(x^{'} , dx) \\, \\alpha_m(x^{'}, x) + \\int_{B\\cap A} \\pi(dx^{'})\\, s(x^{'})$$\n",
    "\n",
    "where it is sufficient:\n",
    "\n",
    "$$\\int_A \\pi(dx) \\int_B q_m(x , dx^{'}) \\, \\alpha_m(x, x^{'}) =  \\int_B \\pi(dx^{'}) \\int_A q_m(x^{'} , dx) \\, \\alpha_m(x^{'}, x)$$\n",
    "\n",
    "and *Assumming* $\\pi(dx)q_m(x, dx^{'})$ has a finite density $f_m(x, x^{'})$ with respect to a symmetric measure $\\xi_m$ on $C\\times C$.\n",
    "Then:\n",
    "\n",
    "\n",
    "$$\\int_A \\pi(dx) \\int_B q_m(x , dx^{'}) \\, \\alpha_m(x, x^{'})  = \\int_A \\int_B \\xi_m(dx, dx^{'}) f_m(x, x^{'}) \\alpha_m(x, x^{'}) =$$\n",
    "$$\\int_B \\int_A \\xi_m(dx^{'}, dx) f_m(x^{'}, x) \\alpha_m(x^{'}, x) =\n",
    "\\int_B \\pi(dx^{'}) \\int_A q_m(x^{'} , dx) \\, \\alpha_m(x^{'}, x)$$\n",
    "\n",
    "\n",
    "then is obviouse that: $\\alpha_m (x , x^{'}) = min\\Bigg\\{1 , \\; \\frac{f_m(x^{'},x)}{f_m(x,x^{'})} \\Bigg\\}$\n",
    "\n",
    "And to switch between two simple subspaces, can been shown that:\n",
    "\n",
    "$$f(x, x^{'}) = p(1 , \\theta^{(1)} | y)\\, j(1,\\theta^{(1)} )\\, q_1(u^{(1)})$$\n",
    "$$f(x^{'}, x) = p(2 , \\theta^{(2)} | y)\\, j(2,\\theta^{(2)} )\\, q_2(u^{(2)}) \\Bigg| \\frac{\\partial (\\theta^{(2)},u^{(2)})}{\\partial (\\theta^{(1)},u^{(1)} )}  \\Bigg|$$\n",
    "\n",
    "\n",
    "with $\\alpha(x, x^{'}) = min \\Bigg\\{ 1, \\frac{p(2 , \\theta^{(2)} | y)\\, j(2,\\theta^{(2)} )\\, q_2(u^{(2)})}{p(1 , \\theta^{(1)} | y)\\, j(1,\\theta^{(1)} )\\, q_1(u^{(1)})}\\Bigg| \\frac{\\partial (\\theta^{(2)},u^{(2)})}{\\partial (\\theta^{(1)},u^{(1)} )}  \\Bigg| \\Bigg\\}$\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "<h3> <center> A geometric approach to transdimentional MCMC </center> </h3>\n",
    "\n",
    "The theoretical results that *Petris and Tardella* have developed, are focused on the idea to build an more automatic approach to multimodel MCMC for the nested-model case.\n",
    "So in this setup we want a sample from a distribution $\\hat \\mu$ (the posterior of a parameter of interest, supported by a sequence of nested hyperplanes in $R^k$. First step is to construct, in a natural fashion, an absolutely continuous distribution $\\hat \\tau$ on $R^k$ and a transformation $\\phi$ from $R^k$ to itself such that $\\hat \\mu = \\hat \\tau \\phi^{-1}$.\n",
    "In this way, even if is not possible to simulate directly from $\\hat \\tau$, it's possible to generate a finite realization $\\zeta_1, ... , \\zeta_n$ of an ergodic MCMC having limiting distribution $\\hat \\tau$, and the approximate a sample from $\\hat \\mu$ with $\\phi(\\zeta_1), ... , \\phi(\\zeta_n)$.\n",
    "\n",
    "##### Simple case example\n",
    "Let's assume for simplicity that we have an unnormalized probability distribution for $\\theta$, having an absolutely continuous component on $R^k$ and a component degenerate at one point (it's assumed to be the origin).So considering the measure on $R^k$:\n",
    "\n",
    "$$\\mu(d\\theta)= f_0(\\theta)\\nu_K(d\\theta) + \\, f_k \\delta_K(d\\theta)$$\n",
    "\n",
    "that we assume to be finite, but not necessarily a probability measure. So $\\hat \\mu = \\frac{\\mu(\\cdot)}{\\mu(R^k)}$ is the probability proportional to $\\mu$.\n",
    "\n",
    "In order to define the function $\\phi$, let $B_k(r) = \\{\\zeta \\in R^k : || \\zeta || \\leq r \\}$\n",
    "be the K-dimensional closed ball of radius r, centered at the origin, and consider the radial\n",
    "contraction:\n",
    "\n",
    "$$\\psi_K(\\zeta, r) = \\frac{\\zeta}{||\\zeta||} (||\\zeta||^k - r^k)^{1/k}, \\quad \\zeta \\in R^k, \\zeta \\notin B_k(r)$$\n",
    "\n",
    "The inverse function, defined for $\\theta \\neq 0$, is the radial expansion K0\n",
    "\n",
    "$$\\psi_K^{-1}(\\theta, r) = \\frac{\\theta}{||\\theta||} (||\\theta||^k + r^k)^{1/k}$$\n",
    "\n",
    "It is not difficult to prove, using polar coordinates, that for any r, both $\\psi_K$ and $\\psi_K^{-1}$ preserve the Lebesgue measure. Thus, roughly speaking, one can use $\\psi_K^{-1}$\n",
    "to move the absolutely continuous part of $\\mu$ away from the origin, temporarily leaving an empty ball $B_k(r)$, and then spread the mass $f_k$ corresponding to the degenerate component of $\\mu$ uniformly into this ball.\n",
    "\n",
    "![](Densities.png)\n",
    "\n",
    "\n",
    "More formally, define:\n",
    "\n",
    "$$g (\\zeta) =\n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\tc\\cdot f_k  & \\mbox{if } \\zeta \\in B_k(r) \\\\\n",
    "\t\tf_0\\{ \\psi_K(\\zeta ; r) \\} & \\mbox{if } \\zeta \\notin B_k(r)\n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "with $c$ and $r$ arbitrary positive constants satisfying $c\\nu_k \\{ B_k(r) \\} = 1$. Then, taking $\\tau(d\\zeta) = g(\\zeta) \\nu_k(d\\zeta)$ and\n",
    "\n",
    "$$\\phi(\\zeta) =\n",
    "\\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t0  & \\mbox{if } \\zeta \\in B_k(r) \\\\\n",
    "\t\t\\psi_K(\\zeta ; r) & \\mbox{if } \\zeta \\notin B_k(r)\n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "\n",
    "we have exactly what we were looking for, namely an absolutely continuous measure $\\tau$ and a\n",
    "function $\\phi$ such that $\\tau \\phi^{-1} = \\mu$. If $f_0$ is continuous, a default convenient choice for $c$ and $r$ can be derived by requiring that $g$ be continuous as well. The value of $g$, as $\\zeta$ approaches the boundary of the ball from outside, tends to $f_0(0)$, so this must be the constant value of $g$ within the ball if one wants this function to be continuous. Hence, $c = f_0(0)/f_k$. \n",
    "\n",
    "Then it's easy to relax the previous properties to nested models with more than one difference in dimensionality, and to the case of more than two nested models.\n",
    "*For further information the quoted paper is in the **references***\n",
    "\n",
    "#### THEOREM\n",
    "\n",
    "In order to give the result in a general form, let $(Z, S_Z, \\tau)$ and $(\\Theta, S_{\\Theta},\\mu)$ be probability spaces, and let $\\phi$ be a measurable function from $Z$ onto $\\Theta$ such that $\\tau \\phi^{-1} = \\mu$. Let $K$ be a transition kernel on $(Z, S_Z)$ for which $\\tau$ is invariant:\n",
    "\n",
    "$$ \\tau(B) = \\int_Z \\tau(d\\zeta) \\, K(\\zeta ; B)  \\quad  \\forall B \\in S_z$$\n",
    "\n",
    "Consider $\\tau^{*}(B | \\phi(\\zeta)) = \\theta$, a regular version of $\\tau$ given $\\phi^{-1} \\, S_{\\Theta}$, and define a transition kernel $J$ from $\\Theta$ to $Z$ by setting\n",
    "\n",
    "$$ J(\\theta, B) =  \\tau^{*}(B | \\theta) $$\n",
    "\n",
    "\n",
    "**THEOREM**. Considera Markovc hain $\\tilde \\theta_0, \\tilde\\theta_1, ...$ on $(\\Theta, S_{\\Theta})$, whose transition are described by the following steps:\n",
    "1. Draw $\\tilde \\zeta_{t,0}$ according to $J(\\tilde \\theta_t, \\cdot)$.\n",
    "2. Draw $\\tilde \\zeta_{t,1}$ according to $K( \\tilde \\zeta_{t,0}; \\cdot )$.\n",
    "3. Set $\\tilde\\theta = \\phi (\\tilde \\zeta_{t,1})$.\n",
    "\n",
    "\n",
    "Let H denote the corresponding transition kernel, i.e.,\n",
    "\n",
    "$$H(\\theta; A) = \\int_z J(\\theta; d\\zeta) \\cdot K(\\zeta; \\phi^{-1}A)  \\quad  \\forall \\theta \\in \\Theta, \\; \\; A \\in S_{\\Theta} $$\n",
    "\n",
    "Then $\\mu$ is an invariant measure for $H$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <center> Model Selection by transdimentional MCMC for Ar(p) model </center> </h2>\n",
    " \n",
    "\n",
    "The Autoregressive model is a simple model that fit the mean by a simple regression on the last p values in time:\n",
    "\n",
    "$$y_t = \\sum_{j = 1}^p \\alpha_j \\cdot y_{t-j} + \\epsilon , \\quad \\epsilon \\sim N(0,1)$$\n",
    "\n",
    "The goal of my simulation is to compute an approximate posterior distribution on the number of $p$ backward coefficient that we need for a given timeseries.\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(\"HI\",quietly = T)\n",
    "## create data\n",
    "time_series <- arima.sim(list(ar=c(.9, -.2, 0.2)),n=10000)\n",
    "\n",
    "\n",
    "# creation matrix for bayesian regression\n",
    "l = 10000\n",
    "X = cbind(time_series[-c(1,l,l-1,l-2)], time_series[-c(1,2, l,l-1)],\n",
    "          time_series[-c(1,2, 3, l)], time_series[-c(1,2, 3, 4)])\n",
    "\n",
    "\n",
    "### posterior density for Ar(4), Ar(3), Ar(2), Ar(1)\n",
    "ldens.list <- list(posterior.beta.ar.4 <- function(b.hat , mean = c(0,0,0,0)){\n",
    "  -sum((time_series[-c(l,l-1, l-2, l-3)] - t(b.hat%*% t(X[,c(1,2,3,4)])))**2)/2} ,\n",
    "                   posterior.beta.ar.3 <- function(b.hat , mean = c(0,0,0)){\n",
    "  -sum((time_series[-c(l,l-1, l-2, l-3)] - t(b.hat%*% t(X[,c(1,2,3)])))**2)/2} ,\n",
    "                   posterior.beta.ar.2 <- function(b.hat , mean = c(0,0)){\n",
    "  -sum((time_series[-c(l,l-1, l-2, l-3)] - t(b.hat%*% t(X[,c(1,2)])))**2)/2} ,\n",
    "                   posterior.beta.ar.1 <- function(b.hat , mean = c(0)){\n",
    "  -sum((time_series[-c(l,l-1, l-2, l-3)] - b.hat*X[,1])**2)/2})\n",
    "\n",
    "### creation of ausiliar density\n",
    "trans.mix <- function(y) {\n",
    "  trans.dens(y, ldens.list=ldens.list, which.models=0:3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "trans.rmix <- arms(c(0,0,0,0), trans.mix, \n",
    "                   function(b.hat, mean) (min(b.hat)>=-1)*(max(b.hat)<1),\n",
    "                   500)\n",
    "rmix <- trans.dens(y=trans.rmix, ldens.list=ldens.list,\n",
    "                   which.models=0:3, back.transform = TRUE)\n",
    "options(warn=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2 \n",
       "0.028 0.966 0.006 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(rmix[,2])/nrow(rmix) ### Posterior aproximated distribution for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 "
     ]
    }
   ],
   "source": [
    "    ##### Simulation \n",
    "    check <- rep(0, 100)\n",
    "    for(sim in 1:100){\n",
    "        proof = 0\n",
    "        while(proof == 0){\n",
    "            p <- sample(c(1,2,3,4),1,replace = T)\n",
    "            ar <- c(runif(p, -1,1))\n",
    "            if(all(abs(polyroot(c(1,-ar)))>1)){\n",
    "                cat(sim,'')\n",
    "                proof = 1\n",
    "                break\n",
    "            }        \n",
    "        }\n",
    "        try(time_series <- arima.sim(list(ar=ar), n=10000))\n",
    "        l = length(time_series)\n",
    "        X = cbind(time_series[-c(1,l,l-1,l-2)], time_series[-c(1,2, l,l-1)],\n",
    "                  time_series[-c(1,2, 3, l)], time_series[-c(1,2, 3, 4)])\n",
    "        options(warn=-1)\n",
    "        trans.rmix <- arms(c(0,0,0,0), trans.mix, function(b.hat, mean) (min(b.hat)>=-1)*(max(b.hat)<1),\n",
    "                           300)\n",
    "        rmix <- trans.dens(y=trans.rmix, ldens.list=ldens.list,\n",
    "                           which.models=0:3, back.transform = TRUE)\n",
    "        options(warn=0)\n",
    "        check[sim] <- (p == (4 - as.numeric(names(which.max(table(rmix[,2]))))))\n",
    "    }\n",
    "    sum(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "77"
      ],
      "text/latex": [
       "77"
      ],
      "text/markdown": [
       "77"
      ],
      "text/plain": [
       "[1] 77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transdimentional MCMC using parametrization for AR(p) with Partial Autocorrelations\n",
    "\n",
    "As noted by the Durbinâ€“Levinson recursion for the $AR(p)$ model, it's possible to define a one-to-one transformation $\\phi(\\zeta)=\\alpha$, from the space of autoregressive coefficients $\\alpha$ and the partial autocorrelation $\\zeta$.\n",
    "\n",
    "Furthermore in the paper of \"A. I. McLeod and Y. Zhang\" is shown that the log-likelihood function can be written as:\n",
    "\n",
    "$$l(\\;\\zeta, \\sigma^2) = - \\frac{n}{2}log(\\sigma^2) - \\frac{1}{2}log(g_p) - \\frac{1}{2 \\sigma^2}S(\\zeta)$$\n",
    "\n",
    "Maximizing over $\\sigma^2$ and dropping constant terms:\n",
    "\n",
    "$$l_c(\\; \\zeta)= - \\frac{n}{2}log(\\hat \\sigma^2) - \\frac{1}{2}log(g_p)$$\n",
    "\n",
    "where:    $\\hat \\sigma^2 = \\frac{S(\\, \\zeta)}{n}, \\quad S(\\, \\zeta) = \\beta^T D \\beta, \\quad \\beta=(-1, \\phi_1(\\zeta),..., \\phi_p(\\zeta)) \\quad$ \n",
    "and $D$ is the $(p+1)\\times(p+1)$ matrix with $(i,j)$th entry, $D_{i,j}= z_iz_j + ... + z_{n-j}z_{n-i}\\quad$\n",
    "\n",
    "then\n",
    "$$g_p=det(\\frac{\\Gamma}{\\sigma^2}) = \\prod_{i=1}^p (1 - \\zeta_i^2)^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(FitAR, quietly = T)\n",
    "time_series <- arima.sim(list(ar=c(.9, -.2, 0.2)),n=10000)\n",
    "## log likelihood with prior unif in (-1,1)\n",
    "log.lik <- function(zeta){\n",
    "    p= length(zeta)\n",
    "    D <- matrix(nrow = p+1 ,ncol = p+1)\n",
    "    n = length(time_series)\n",
    "    for(i in 1:(p+1)){\n",
    "        for(j in 1:(p+1)){\n",
    "            D[i,j] = time_series[i:(n-j)]%*%time_series[j:(n-i)]\n",
    "        }\n",
    "    }\n",
    "    beta <- c(-1, PacfToAR(zeta))\n",
    "    S.zeta <- beta%*%D%*%beta\n",
    "    g.p <- prod((1- zeta**2)**-(1:p))\n",
    "    return(-(n/2)*log(S.zeta/n) - (1/2)*log(g.p))\n",
    "}\n",
    "\n",
    "## all posterior given the model\n",
    "ldens.list.2 <- list(\"AR(4)\" = log.lik, \"AR(3)\" = log.lik,\n",
    "                   \"AR(2)\" = log.lik, \"AR(1)\" = log.lik)\n",
    "\n",
    "### creation of ausiliar density\n",
    "trans.mix.2 <- function(y) {\n",
    "  trans.dens(y, ldens.list=ldens.list.2, which.models=0:3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     1      2      3 \n",
       "0.9654 0.0002 0.0344 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(warn=-1)\n",
    "trans.rmix.2 <- arms(c(0,0,0,0), trans.mix.2, function(zeta) (min(zeta)>=-1)*(max(zeta)<1),\n",
    "                   5000)\n",
    "rmix <- trans.dens(y=trans.rmix.2, ldens.list=ldens.list.2,\n",
    "                   which.models=0:3, back.transform = TRUE)\n",
    "options(warn=0)\n",
    "table(rmix[,2])/nrow(rmix) ### Posterior aproximated distribution for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 "
     ]
    },
    {
     "data": {
      "text/html": [
       "84"
      ],
      "text/latex": [
       "84"
      ],
      "text/markdown": [
       "84"
      ],
      "text/plain": [
       "[1] 84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Simulation \n",
    "check <- rep(0, 100)\n",
    "for(sim in 1:1){\n",
    "    proof = 0\n",
    "    while(proof == 0){\n",
    "        p <- sample(c(1,2,3,4),1,replace = T)\n",
    "        ar <- c(runif(p, -1,1))\n",
    "        if(all(abs(polyroot(c(1,-ar)))>1)){\n",
    "            cat(sim,'')\n",
    "            proof = 1\n",
    "            break\n",
    "        }        \n",
    "    }\n",
    "    try(time_series <- arima.sim(list(ar=ar), n=10000))\n",
    "    options(warn=-1)\n",
    "    trans.rmix.2 <- arms(c(0,0,0,0), trans.mix.2,\n",
    "                         function(zeta) (min(zeta)>=-1)*(max(zeta)<1),\n",
    "                   300)\n",
    "    rmix <- trans.dens(y=trans.rmix.2, ldens.list=ldens.list.2,\n",
    "                       which.models=0:3, back.transform = TRUE)\n",
    "    options(warn=0)\n",
    "    check[sim] <- (p == (4 - as.numeric(names(which.max(table(rmix[,2]))))))\n",
    "}\n",
    "sum(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "\n",
    "***Peter J. Green : *** [Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determination](http://links.jstor.org/sici?sici=0006-3444%28199512%2982%3A4%3C711%3ARJMCMC%3E2.0.CO%3B2-F)\n",
    "\n",
    "***Giovanni PETRIS and Luca TARDELLA : *** [A Geometric Approach to Transdimentional Markov Chain Monte Carlo](http://www.jstor.org/stable/3315857?origin=JSTOR-pdf&seq=1#page_scan_tab_contents)\n",
    "\n",
    "***Giovanni PETRIS and Luca TARDELLA : *** [Transdimensional Markov Chain Monte Carlo Using Hyperplane Inflation in Locally Nested Spaces](http://www.dss.uniroma1.it/sites/default/files/vecchie-pubblicazioni/RT_2_2006_Petris.pdf)\n",
    "\n",
    "***Giovanni PETRIS and Luca TARDELLA : *** [HI: Simulation from distributions supported by nested hyperplanes](https://cran.r-project.org/web/packages/HI/index.html)\n",
    "\n",
    "***W. K. Hastings : ***[Monte Carlo Sampling Methods Using Markov Chains and Their Applications](https://www.jstor.org/stable/2334940?seq=1#page_scan_tab_contents)\n",
    "\n",
    "\n",
    "***O. BarnDorff-Nielsen and G.Schou : ***[On the Parametrization of Autoregressive Models by Partial Autocorrelations](https://ac.els-cdn.com/0047259X73900304/1-s2.0-0047259X73900304-main.pdf?_tid=7a7dde12-1685-11e8-aaa4-00000aab0f6c&acdnat=1519162497_09751a5db5eb36b5991bb8e0e1e95650)\n",
    "\n",
    "***A.I. McLeod, Ying Zhang and Changjiang Xu : ***[FitAR: Subset AR Model Fitting](https://cran.r-project.org/web/packages/FitAR/index.html)\n",
    "\n",
    "***A. I. McLeod and Y. Zhang : ***[Partial Autocorrelation Parameterization for Subset Autoregression](http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9892.2006.00481.x/full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [Anaconda3]",
   "language": "R",
   "name": "R [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
